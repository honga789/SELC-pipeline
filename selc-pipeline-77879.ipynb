{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12568531,"sourceType":"datasetVersion","datasetId":7937169},{"sourceId":12580615,"sourceType":"datasetVersion","datasetId":7911326}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import copy\nimport os\nimport random\nimport time\nfrom typing import Literal, Optional, Tuple, List\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as T\n\nfrom sklearn.mixture import GaussianMixture\n\nfrom transformers import BertModel, get_linear_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:15.815939Z","iopub.execute_input":"2025-07-31T06:39:15.816133Z","iopub.status.idle":"2025-07-31T06:39:54.741898Z","shell.execute_reply.started":"2025-07-31T06:39:15.816116Z","shell.execute_reply":"2025-07-31T06:39:54.741102Z"}},"outputs":[{"name":"stderr","text":"2025-07-31 06:39:38.713469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753943979.075071      71 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753943979.188704      71 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"IMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\n\nclass _TrainDataset(Dataset):\n    \"\"\"\n    Dataset train chung cho image/text.\n    - Image: trả Tensor (C,H,W) sau Resize & Normalize (ImageNet).\n    - Text: trả string thô; tokenize ở collate_fn để padding theo batch.\n    Trả về: (x, y_noisy, index)\n    \"\"\"\n    def __init__(\n        self,\n        df: pd.DataFrame,\n        data_column: str,\n        noisy_labels: np.ndarray,\n        data_type: str,\n        image_dir: Optional[str] = None,\n        image_size: int = 224,\n    ):\n        assert data_type in {\"image\", \"text\"}, \"data_type phải là 'image' hoặc 'text'\"\n        self.df = df.reset_index(drop=True)\n        self.data_column = data_column\n        self.noisy_labels = noisy_labels.astype(np.int64)\n        self.data_type = data_type\n        self.image_dir = image_dir\n        self.image_size = image_size\n\n        if self.data_type == \"image\":\n            if not self.image_dir:\n                raise ValueError(\"image_dir là bắt buộc khi data_type='image'.\")\n            self.transform = T.Compose([\n                T.Resize((self.image_size, self.image_size)),  # không augmentation, chỉ resize cố định\n                T.ToTensor(),\n                T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n            ])\n        else:\n            self.transform = None  # tokenize ở collate_fn\n\n        if len(self.df) != len(self.noisy_labels):\n            raise ValueError(f\"Số dòng CSV ({len(self.df)}) khác số dòng feather/noisy ({len(self.noisy_labels)}).\")\n\n    def __len__(self) -> int:\n        return len(self.df)\n\n    def _load_image(self, fname: str) -> torch.Tensor:\n        path = os.path.join(self.image_dir, fname)\n        with Image.open(path) as im:\n            im = im.convert(\"RGB\")\n        return self.transform(im)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        if self.data_type == \"image\":\n            x = self._load_image(str(row[self.data_column]))\n        else:\n            # text thô; collate_fn sẽ tokenize\n            x = str(row[self.data_column])\n        y = int(self.noisy_labels[idx])  # nhãn nhiễu để train (đã là 0..C-1 theo yêu cầu)\n        return x, torch.tensor(y, dtype=torch.long), idx\n\n\ndef _make_text_collate_fn(max_length: int = 512, pretrained_name: str = \"bert-base-uncased\"):\n    \"\"\"\n    Collate cho text: tokenize theo batch -> dict tensors (input_ids, attention_mask, token_type_ids).\n    Trả về: (inputs_dict, labels, indices)\n    \"\"\"\n    from transformers import BertTokenizerFast\n    tokenizer = BertTokenizerFast.from_pretrained(pretrained_name)\n\n    def collate(batch: List[Tuple[str, torch.Tensor, int]]):\n        texts = [b[0] for b in batch]\n        labels = torch.stack([b[1] for b in batch], dim=0)\n        indices = torch.tensor([b[2] for b in batch], dtype=torch.long)\n        tokenized = tokenizer(\n            texts,\n            padding=True,\n            truncation=True,\n            max_length=max_length,\n            return_tensors=\"pt\",\n        )\n        # đảm bảo có token_type_ids (BERT sử dụng)\n        if \"token_type_ids\" not in tokenized:\n            tokenized[\"token_type_ids\"] = torch.zeros_like(tokenized[\"input_ids\"])\n        return dict(tokenized), labels, indices\n\n    return collate\n\n\nclass TrainDataLoader:\n    \"\"\"\n    Dataloader chỉ cho TRAIN.\n\n    Args:\n        csv_path: đường dẫn CSV (cột data & cột label sạch).\n        feather_path: file feather có cột 'label' = nhãn NHIỄU (0..C-1), cùng thứ tự với CSV.\n        data_column: tên cột dữ liệu (text hoặc tên file ảnh) trong CSV.\n        label_column: tên cột nhãn sạch trong CSV (0..C-1).\n        image_dir: thư mục chứa ảnh (bắt buộc nếu data_type='image').\n        data_type: 'image' hoặc 'text'.\n        batch_size: kích thước batch.\n        num_workers: số worker cho DataLoader (mặc định 4).\n        image_size: kích thước resize ảnh (mặc định 224).\n        text_max_length: max_length khi tokenize BERT (mặc định 512).\n    \"\"\"\n    def __init__(\n        self,\n        csv_path: str,\n        feather_path: str,\n        data_column: str,\n        label_column: str,\n        image_dir: Optional[str],\n        data_type: str,\n        batch_size: int,\n        num_workers: int = 4,\n        image_size: int = 224,\n        text_max_length: int = 512,\n    ):\n        self.csv_path = csv_path\n        self.feather_path = feather_path\n        self.data_column = data_column\n        self.label_column = label_column\n        self.image_dir = image_dir\n        self.data_type = data_type\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.image_size = image_size\n        self.text_max_length = text_max_length\n\n        # Đọc dữ liệu\n        df = pd.read_csv(self.csv_path)\n        if self.data_column not in df.columns or self.label_column not in df.columns:\n            raise ValueError(f\"CSV phải có cột '{self.data_column}' và '{self.label_column}'.\")\n        fdf = pd.read_feather(self.feather_path)\n        if \"label\" not in fdf.columns:\n            raise ValueError(\"Feather phải có cột 'label' (nhãn nhiễu).\")\n\n        # Lấy clean/noisy labels (đã 0..C-1 theo yêu cầu)\n        self.clean_labels = df[self.label_column].to_numpy(dtype=np.int64)\n        self.noisy_labels = fdf[\"label\"].to_numpy(dtype=np.int64)\n\n        # Dataset\n        self.train_dataset = _TrainDataset(\n            df=df,\n            data_column=self.data_column,\n            noisy_labels=self.noisy_labels,\n            data_type=self.data_type,\n            image_dir=self.image_dir,\n            image_size=self.image_size,\n        )\n\n        # Collate cho text\n        collate = _make_text_collate_fn(max_length=self.text_max_length) if self.data_type == \"text\" else None\n\n        pin_mem = torch.cuda.is_available()\n        self.trainloader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=self.num_workers,\n            pin_memory=pin_mem,\n            persistent_workers=(self.num_workers > 0),\n            collate_fn=collate,\n        )\n\n    def run(self) -> Tuple[DataLoader, np.ndarray, np.ndarray]:\n        \"\"\"Trả: (trainloader, noisy_labels, clean_labels).\"\"\"\n        return self.trainloader, self.noisy_labels, self.clean_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.742651Z","iopub.execute_input":"2025-07-31T06:39:54.743114Z","iopub.status.idle":"2025-07-31T06:39:54.758719Z","shell.execute_reply.started":"2025-07-31T06:39:54.743094Z","shell.execute_reply":"2025-07-31T06:39:54.757936Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"'''ResNet in PyTorch.\nBasicBlock and Bottleneck module is from the original ResNet paper:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\nPreActBlock and PreActBottleneck module is from the later paper:\n[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n'''\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out)\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out)\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = conv3x3(3, 64)  # number 1 indicates how many channels\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        # [CHANGE] dùng adaptive pool để hỗ trợ mọi input size (32, 96, 224, ...)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n        self.c_linear = nn.Linear(512 * block.expansion, 1)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x, lin=0, lout=5):\n        out = x\n        # [CHANGE] an toàn biến trả về khi lout <= 4\n        feature = None\n        out_c = None\n\n        if lin < 1 and lout > -1:\n            out = self.conv1(out)\n            out = self.bn1(out)\n            out = F.relu(out)\n        if lin < 2 and lout > 0:\n            out = self.layer1(out)\n        if lin < 3 and lout > 1:\n            out = self.layer2(out)\n        if lin < 4 and lout > 2:\n            out = self.layer3(out)\n        if lin < 5 and lout > 3:\n            out = self.layer4(out)\n        if lout > 4:\n            # [CHANGE] thay vì F.avg_pool2d(out, 4)\n            out = self.avgpool(out)\n            out = out.view(out.size(0), -1)\n            feature = out\n            out_c = self.c_linear(out)\n            out = self.linear(out)\n        return out, feature, out_c\n\n\ndef ResNet34(num_classes):\n    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.759656Z","iopub.execute_input":"2025-07-31T06:39:54.759908Z","iopub.status.idle":"2025-07-31T06:39:54.795830Z","shell.execute_reply.started":"2025-07-31T06:39:54.759890Z","shell.execute_reply":"2025-07-31T06:39:54.795171Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class BertTextClassifier(nn.Module):\n    \"\"\"\n    BERT -> Dropout -> Linear(num_classes)\n    Trả về: logits (B, C), feature (B, H), out_c (B, 1)\n    - logits: dùng cho loss CE (multi-class)\n    - feature: embedding đã qua dropout, trước classifier\n    - out_c: logit 1 chiều (giữ giao diện với pipeline hiện tại)\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int,\n        pretrained_name: str = \"bert-base-uncased\",\n        dropout: float = 0.3,\n        freeze_bert: bool = False,\n    ):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(pretrained_name)\n        hidden = self.bert.config.hidden_size\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(hidden, num_classes)\n        self.c_linear = nn.Linear(hidden, 1)  # giữ pipeline: trả thêm out_c\n\n        if freeze_bert:\n            for p in self.bert.parameters():\n                p.requires_grad = False\n\n    def forward(self, inputs, lin: int = 0, lout: int = 2):\n        \"\"\"\n        inputs: dict có các keys 'input_ids', 'attention_mask', (tuỳ tokenizer có thể có 'token_type_ids')\n        lin/lout để giữ chữ ký giống ResNet; ở đây không cắt tầng nên bỏ qua.\n        \"\"\"\n        # Đảm bảo có token_type_ids (một số tokenizer có thể không tạo)\n        if isinstance(inputs, dict) and \"token_type_ids\" not in inputs:\n            inputs = dict(inputs)  # clone shallow để không đụng batch gốc\n            inputs[\"token_type_ids\"] = torch.zeros_like(inputs[\"input_ids\"])\n\n        outputs = self.bert(**inputs, return_dict=True)\n        # pooled_output có sẵn (tanh( W * CLS )), nếu vì lý do nào đó None thì fallback về CLS token\n        if outputs.pooler_output is not None:\n            pooled = outputs.pooler_output  # (B, H)\n        else:\n            pooled = outputs.last_hidden_state[:, 0]  # (B, H) lấy token [CLS]\n\n        feat = self.dropout(pooled)      # feature dùng để phân loại\n        out_c = self.c_linear(feat)      # (B, 1) - để khớp pipeline\n        logits = self.classifier(feat)   # (B, num_classes)\n        return logits, feat, out_c\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.796638Z","iopub.execute_input":"2025-07-31T06:39:54.796909Z","iopub.status.idle":"2025-07-31T06:39:54.818619Z","shell.execute_reply.started":"2025-07-31T06:39:54.796887Z","shell.execute_reply":"2025-07-31T06:39:54.818100Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ----- helper: per-sample losses -----\n@torch.no_grad()\ndef _per_sample_losses(\n    model: torch.nn.Module,\n    trainloader: torch.utils.data.DataLoader,\n    device: torch.device,\n    data_type: Literal[\"image\", \"text\"],\n    num_samples: int,\n    show_tqdm: bool = True,\n    use_amp: bool = False, # [AMP] Thêm tham số để bật/tắt autocast\n) -> np.ndarray:\n    model.eval()\n    losses = torch.empty(num_samples, dtype=torch.float32, device=device)\n    it = tqdm(trainloader, desc=\"Eval per-sample loss\", unit=\"batch\", leave=False, disable=not show_tqdm)\n    for batch in it:\n        if data_type == \"text\":\n            inputs, labels, index = batch\n            inputs = {k: v.to(device, non_blocking=True) for k, v in inputs.items()}\n        else:\n            inputs, labels, index = batch\n            inputs = inputs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        index  = index.to(device, non_blocking=True)\n\n        # [AMP] Bọc forward pass với autocast để tăng tốc tính toán trên GPU\n        with autocast(\"cuda\", enabled=use_amp):\n            logits, _, _ = model(inputs)\n            loss_vec = F.cross_entropy(logits, labels, reduction=\"none\")\n        \n        losses[index] = loss_vec\n    return losses.detach().cpu().numpy()\n\n# ----- [CHANGE] normalize losses per epoch -----\ndef _normalize_losses(\n    losses: np.ndarray,\n    method: Literal[\"minmax\", \"robust\", \"none\"] = \"minmax\",\n    eps: float = 1e-8,\n) -> np.ndarray:\n    \"\"\"Chuẩn hoá loss theo epoch để M1 so sánh được giữa các epoch.\"\"\"\n    x = losses.astype(np.float64)\n    # loại bỏ inf/nan về giá trị hữu hạn an toàn\n    x = np.nan_to_num(x, nan=0.0, posinf=np.max(x[np.isfinite(x)]) if np.isfinite(x).any() else 0.0, neginf=0.0)\n\n    if method == \"none\":\n        return x\n\n    if method == \"minmax\":\n        lo, hi = np.min(x), np.max(x)\n        denom = max(hi - lo, eps)\n        z = (x - lo) / denom\n        return np.clip(z, 0.0, 1.0)\n\n    # robust z-score theo median/MAD (đơn vị z, không ép 0..1)\n    med = np.median(x)\n    mad = np.median(np.abs(x - med))\n    denom = max(mad * 1.4826, eps)  # 1.4826 ~ chuyển MAD -> sigma\n    return (x - med) / denom\n\n# ----- helper: M1 from losses -----\ndef _m1_from_losses(losses: np.ndarray, random_state: int = 42) -> float:\n    x = losses.reshape(-1, 1).astype(np.float64)\n    # (sau normalize, x đã hữu hạn)\n    if x.shape[0] < 3:\n        return 0.0\n    gmm = GaussianMixture(n_components=2, random_state=random_state, covariance_type=\"full\")\n    gmm.fit(x)\n    mu = np.sort(gmm.means_.flatten())\n    return float(abs(mu[1] - mu[0]))\n\n# ----- main: estimate es by M1 -----\ndef estimate_es_m1(\n    model: torch.nn.Module,\n    trainloader: torch.utils.data.DataLoader,\n    device: torch.device,\n    data_type: Literal[\"image\", \"text\"],\n    *,\n    max_scan_epochs: int = 60,\n    lr: float = 2e-2,\n    optimizer_name: Literal[\"SGD\", \"AdamW\"] = \"SGD\",\n    weight_decay: float = 1e-3,\n    momentum: float = 0.9,\n    random_state: int = 42,\n    patience: Optional[int] = None,\n    clone_model: bool = True,\n    show_tqdm: bool = True,\n    normalize: Literal[\"minmax\", \"robust\", \"none\"] = \"minmax\",\n    use_amp: bool = True, # [AMP] Thêm tùy chọn để bật/tắt AMP\n) -> Tuple[int, List[float]]:\n    work_model = copy.deepcopy(model) if clone_model else model\n    work_model.to(device)\n    if optimizer_name == \"SGD\":\n        opt = torch.optim.SGD(work_model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n    else:\n        opt = torch.optim.AdamW(work_model.parameters(), lr=lr, weight_decay=weight_decay)\n    ce = torch.nn.CrossEntropyLoss()\n\n    # [AMP] Chỉ bật AMP khi có GPU và được người dùng cho phép\n    is_amp_enabled = use_amp and device.type == \"cuda\"\n    if is_amp_enabled:\n        # [AMP] Khởi tạo GradScaler để quản lý việc scale gradient\n        scaler = GradScaler(\"cuda\", enabled=is_amp_enabled)\n\n    num_samples = len(trainloader.dataset)\n    best_epoch, best_m1, hist_m1, no_imp = 1, -float(\"inf\"), [], 0\n\n    epoch_iter = tqdm(range(1, max_scan_epochs + 1), desc=\"Scan epochs (M1)\", unit=\"epoch\",\n                      disable=not show_tqdm)\n    for epoch in epoch_iter:\n        work_model.train()\n        train_it = tqdm(trainloader, desc=f\"Train e{epoch}\", unit=\"batch\", leave=False, disable=not show_tqdm)\n        for batch in train_it:\n            if data_type == \"text\":\n                inputs, labels, _ = batch\n                inputs = {k: v.to(device, non_blocking=True) for k, v in inputs.items()}\n            else:\n                inputs, labels, _ = batch\n                inputs = inputs.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n\n            # [AMP] Bọc forward pass và tính loss bằng autocast\n            with autocast(\"cuda\", enabled=is_amp_enabled):\n                logits, _, _ = work_model(inputs)\n                loss = ce(logits, labels)\n\n            opt.zero_grad(set_to_none=True)\n            \n            # [AMP] Sử dụng scaler để thực hiện backward và step nếu AMP được bật\n            if is_amp_enabled:\n                scaler.scale(loss).backward()\n                scaler.step(opt)\n                scaler.update()\n            else:\n                loss.backward()\n                opt.step()\n\n        # [AMP] Truyền cờ is_amp_enabled vào hàm tính loss\n        losses_np = _per_sample_losses(work_model, trainloader, device, data_type, num_samples, show_tqdm=show_tqdm, use_amp=is_amp_enabled)\n        losses_np = _normalize_losses(losses_np, method=normalize)\n        m1 = _m1_from_losses(losses_np, random_state=random_state)\n        hist_m1.append(m1)\n        print(f\"[Scan][Epoch {epoch}] M1={m1:.6f}\")\n        epoch_iter.set_postfix_str(f\"M1={m1:.6f}\")\n\n        if m1 > best_m1:\n            best_m1, best_epoch, no_imp = m1, epoch, 0\n        else:\n            no_imp += 1\n            if patience is not None and no_imp >= patience:\n                print(\"Early stop triggered!\")\n                epoch_iter.set_postfix_str(f\"M1={m1:.6f} (early stop)\")\n                break\n\n    print(f\"=> estimated_es (M1) = {best_epoch}\")\n    return best_epoch, hist_m1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.819268Z","iopub.execute_input":"2025-07-31T06:39:54.819495Z","iopub.status.idle":"2025-07-31T06:39:54.843699Z","shell.execute_reply.started":"2025-07-31T06:39:54.819478Z","shell.execute_reply":"2025-07-31T06:39:54.843171Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ----- Lớp Loss của SELC (Giữ nguyên logic gốc) -----\nclass SELCLoss(nn.Module):\n    def __init__(self, labels, num_classes, es=10, momentum=0.9, device='cuda'):\n        super(SELCLoss, self).__init__()\n        self.num_classes = num_classes\n        self.soft_labels = torch.zeros(len(labels), num_classes, dtype=torch.float).to(device)\n        self.soft_labels[torch.arange(len(labels)), labels] = 1\n        self.es = es\n        self.momentum = momentum\n        self.CEloss = nn.CrossEntropyLoss()\n\n    def forward(self, logits, labels, index, epoch):\n        pred = F.softmax(logits, dim=1)\n        if epoch <= self.es:\n            ce = self.CEloss(logits, labels)\n            return ce\n        else:\n            pred_detach = F.softmax(logits.detach(), dim=1)\n            self.soft_labels[index] = self.momentum * self.soft_labels[index] + (1 - self.momentum) * pred_detach\n            \n            selc_loss = -torch.sum(torch.log(pred) * self.soft_labels[index], dim=1)\n            return selc_loss.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.845369Z","iopub.execute_input":"2025-07-31T06:39:54.845579Z","iopub.status.idle":"2025-07-31T06:39:54.868921Z","shell.execute_reply.started":"2025-07-31T06:39:54.845562Z","shell.execute_reply":"2025-07-31T06:39:54.868375Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# [CONFIG] Thay đổi các giá trị trong dict này để chạy với dataset khác\nconfig = {\n    \"dataset_name\": \"CIFAR-10_sym40\",\n    \"csv_path\": \"/kaggle/input/cifar10-test/Cifar10-test.csv\",\n    \"feather_path\": \"/kaggle/input/cifar10-test/cifar10-test-clip-b16-noise/cifar10-test_sym40.feather\",\n    \"data_column\": \"image_name\",\n    \"label_column\": \"label\",\n    \"image_dir\": \"/kaggle/input/cifar10-test/images\",\n    \"data_type\": \"image\",      # 'image' hoặc 'text'\n    \"batch_size\": 128,         # Mặc định từ src gốc\n    \"num_epochs\": 200,         # Mặc định từ src gốc\n    \"es\": None,                  # Đặt None để tự động ước tính, hoặc điền số nguyên (vd: 40)\n    \"alpha\": 0.9,              # Mặc định từ src gốc\n    \"log_interval\": 30,\n    \"seed\": 42,\n    \"max_duration_seconds\": 11 * 3600  # Thời gian tối đa thực thi, đặt None nếu không giới hạn\n}\n\n# ----- Tự động thiết lập siêu tham số -----\nif config[\"data_type\"] == 'image':\n    hparams = {\"lr\": 0.02, \"op\": \"SGD\", \"lr_s\": \"MultiStepLR\"}\nelse: # text\n    hparams = {\"lr\": 2e-5, \"op\": \"AdamW\", \"lr_s\": \"LinearWarmup\"}\nprint(f\"Running with config: {config['dataset_name']}\")\nprint(f\"Hyperparameters: {hparams}\")\n\n# ----- Thiết lập môi trường -----\nstart_time = time.time()\nrandom.seed(config[\"seed\"])\nnp.random.seed(config[\"seed\"])\ntorch.manual_seed(config[\"seed\"])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(config[\"seed\"])\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = torch.cuda.is_available()\n\n# ----- Tải dữ liệu -----\nloader = TrainDataLoader(\n    csv_path=config[\"csv_path\"], feather_path=config[\"feather_path\"],\n    data_column=config[\"data_column\"], label_column=config[\"label_column\"],\n    image_dir=config[\"image_dir\"], data_type=config[\"data_type\"],\n    batch_size=config[\"batch_size\"]\n)\ntrainloader, noisy_labels, clean_labels = loader.run()\nnum_classes = int(np.max(clean_labels)) + 1\n\n# ----- Khởi tạo Model  -----\nif config[\"data_type\"] == 'image':\n    model = ResNet34(num_classes=num_classes)\nelse:\n    model = BertTextClassifier(num_classes=num_classes)\n    \n# [DataParallel] Tự động sử dụng nhiều GPU nếu có\nif torch.cuda.is_available() and torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel.\")\n    model = nn.DataParallel(model)\nmodel.to(device)\n\n# ----- Ước tính Turning Point (nếu cần) -----\nes = config[\"es\"]\nif es is None:\n    print(\"`es` is None, starting automatic turning point estimation...\")\n    scan_lr = hparams[\"lr\"]\n    scan_op = hparams[\"op\"]\n    \n    estimated_es_val, _ = estimate_es_m1(\n        model=model, trainloader=trainloader, device=device, data_type=config[\"data_type\"],\n        max_scan_epochs=60, lr=scan_lr, optimizer_name=scan_op, weight_decay=1e-3,\n        momentum=0.9, random_state=config[\"seed\"], patience=12, clone_model=True,\n        show_tqdm=True, normalize=\"minmax\", use_amp=use_amp\n    )\n    # [ES] Áp dụng công thức Te = T - 10 từ paper\n    es = max(1, estimated_es_val - 10)\n    # es = estimated_es_val\n    print(f\"Automatic estimation finished. Using es = {es} (T={estimated_es_val} - 10)\")\nelse:\n    print(f\"Using predefined es = {es}\")\n\n# ----- Khởi tạo Optimizer, Scheduler và Loss -----\nif hparams[\"op\"] == \"SGD\":\n    optimizer = optim.SGD(model.parameters(), lr=hparams[\"lr\"], momentum=0.9, weight_decay=1e-3)\nelse: # AdamW\n    optimizer = optim.AdamW(model.parameters(), lr=hparams[\"lr\"], weight_decay=0.01)\n\nif hparams[\"lr_s\"] == \"MultiStepLR\":\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[40, 80], gamma=0.1)\nelse: # LinearWarmup\n    num_training_steps = len(trainloader) * config[\"num_epochs\"]\n    num_warmup_steps = int(0.1 * num_training_steps)\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n\ncriterion = SELCLoss(noisy_labels, num_classes, es, config[\"alpha\"], device)\nscaler = GradScaler(\"cuda\", enabled=use_amp)\n\n# ----- Vòng lặp huấn luyện chính -----\nprint(f\"\\nStarting main training for {config['num_epochs']} epochs...\")\n\nepoch_iter_main = tqdm(range(1, config[\"num_epochs\"] + 1), desc=\"Main Training\", unit=\"epoch\")\nfor epoch in epoch_iter_main:\n    # [TIME LIMIT] Kiểm tra thời gian ở đầu mỗi epoch\n    if config[\"max_duration_seconds\"] is not None:\n        elapsed_time = time.time() - start_time\n        if elapsed_time >= config[\"max_duration_seconds\"]:\n            print(f\"\\n[TIME LIMIT] Đã đạt giới hạn thời gian {config['max_duration_seconds']} giây. Dừng huấn luyện.\")\n            break # Thoát khỏi vòng lặp training\n        else:\n            print(f\"\\n[Time] Run for: {elapsed_time} giây\")\n        \n    model.train()\n    \n    batch_iter = tqdm(trainloader, desc=f\"Train Epoch {epoch}\", unit=\"batch\", leave=False)\n    total_loss = 0.0\n    \n    for batch_idx, batch in enumerate(batch_iter):\n        if config[\"data_type\"] == \"text\":\n            inputs, target, index = batch[0], batch[1], batch[2]\n            inputs = {k: v.to(device, non_blocking=True) for k,v in inputs.items()}\n        else:\n            inputs, target, index = batch[0], batch[1], batch[2]\n            inputs = inputs.to(device, non_blocking=True)\n        target, index = target.to(device, non_blocking=True), index.to(device, non_blocking=True)\n\n        optimizer.zero_grad(set_to_none=True)\n        \n        # Thực hiện training step\n        with autocast(\"cuda\", enabled=use_amp):\n            output, _, _ = model(inputs)\n            loss = criterion(output, target, index, epoch)\n\n        if use_amp:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            optimizer.step()\n\n        # [SCHEDULER] Cập nhật mỗi BƯỚC cho LinearWarmup\n        if hparams[\"lr_s\"] == \"LinearWarmup\":\n            scheduler.step()\n            \n        total_loss += loss.item()\n\n        # In log theo interval\n        if batch_idx % config['log_interval'] == 0:\n            # Giữ lại định dạng print của file gốc\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(target), len(trainloader.dataset),\n                100. * batch_idx / len(trainloader), loss.item()))\n        \n        current_lr = optimizer.param_groups[0]['lr']\n        batch_iter.set_postfix_str(f\"Loss: {loss.item():.4f} LR: {current_lr:.6f}\")\n\n    # [SCHEDULER] Cập nhật mỗi EPOCH cho MultiStepLR\n    if hparams[\"lr_s\"] == \"MultiStepLR\":\n        scheduler.step()\n        \n    # Cập nhật thông tin loss trung bình lên thanh tqdm của epoch\n    avg_loss_epoch = total_loss / len(trainloader)\n    print(f\"--- End of Epoch {epoch}/{config['num_epochs']} --- Average Loss: {avg_loss_epoch:.4f} ---\")\n    epoch_iter_main.set_postfix_str(f\"Avg Loss: {avg_loss_epoch:.4f}\")\n\nprint(\"Training finished.\")\n\n# ----- Lưu model -----\noutput_dir = f\"./output_{config['dataset_name']}_es{es}_seed{config['seed']}\"\nos.makedirs(output_dir, exist_ok=True)\n\nfinal_model_path = os.path.join(output_dir, \"final_model.pth\")\nif isinstance(model, nn.DataParallel):\n    torch.save(model.module.state_dict(), final_model_path)\nelse:\n    torch.save(model.state_dict(), final_model_path)\nprint(f\"Final model saved to {final_model_path}\")\n\n# --- Calculate metric and save ---\nprint(\"\\nCalculating final correction metrics...\")\n\n_, corrected_labels_tensor = torch.max(criterion.soft_labels, dim=1)\ncorrected_labels = corrected_labels_tensor.cpu().numpy()\n\n# 1. Tính Correction Precision: Trong số các nhãn đã được thay đổi, bao nhiêu % được sửa đúng?\nchanged_mask = (noisy_labels != corrected_labels)\ntotal_changed = np.sum(changed_mask)\n\ncorrectly_fixed_mask = (corrected_labels == clean_labels)\ncorrectly_changed_count = np.sum(changed_mask & correctly_fixed_mask)\nprecision = (correctly_changed_count / total_changed * 100) if total_changed > 0 else 0.0\n\n# 2. Tính Error Rate: Tỷ lệ nhãn sai sau khi đã sửa\nfinal_errors = np.sum(corrected_labels != clean_labels)\nerror_rate = final_errors / len(clean_labels) * 100\n\n# In các chỉ số ra màn hình\nprint(f\"Total labels changed: {total_changed}/{len(clean_labels)}\")\nprint(f\"Correction Precision: {correctly_changed_count}/{total_changed} = {precision:.2f}%\")\nprint(f\"Final Error Rate: {final_errors}/{len(clean_labels)} = {error_rate:.2f}%\")\n\n# Save correct info\nresults_df = pd.DataFrame({\n    'Index': range(len(clean_labels)),\n    'noisy_label': noisy_labels,\n    'fixed_label': corrected_labels,\n    'true_label': clean_labels\n})\nbase_feather_name = os.path.basename(config[\"feather_path\"])\nfile_stem = os.path.splitext(base_feather_name)[0]\nnew_csv_filename = f\"{file_stem}_correction_results.csv\"\ncsv_path = os.path.join(output_dir, new_csv_filename)\nresults_df.to_csv(csv_path, index=False)\nprint(f\"Detailed correction results saved to {csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T06:39:54.869682Z","iopub.execute_input":"2025-07-31T06:39:54.869902Z","execution_failed":"2025-07-31T06:40:35.332Z"}},"outputs":[{"name":"stdout","text":"Running with config: CIFAR-10_sym40\nHyperparameters: {'lr': 0.02, 'op': 'SGD', 'lr_s': 'MultiStepLR'}\nUsing 2 GPUs with DataParallel.\n`es` is None, starting automatic turning point estimation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Scan epochs (M1):   0%|          | 0/60 [00:00<?, ?epoch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81f333b628424d58b5a5ee61260b13b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Train e1:   0%|          | 0/79 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b56f56d022d4dab907cb540788e08bf"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}